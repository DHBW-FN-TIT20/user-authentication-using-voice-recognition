\section{Umsetzung}

\subsection{Technologieentscheidung}
\subsubsection{Versuchssystem}
Aus der Konzeption in Kapitel~\ref{sec:Konzeption} gehen verschiedene Anforderungen an die Technologie hervor.
Durch die Verwendung von neuronalen Netzen werden die verfügbaren Technologien bzw. Programmiersprachen bereits eingeschränkt.
Um weitere Technologieenscheidungen zu treffen muss zunächst eine Programmiersprache ausgewählt werden.
Da in einer Umfrage unter Machine-Learning-Entwicklern und Data Scientists 57\% Python als Programmiersprache nutzen und 33\% diese sogar priorisieren, wird für dieses Projekt Python als Programmiersprache festgelegt \autocite[vgl. ][S. 16]{vision_mobile_state_2017}.
In einer allgemeinen Umfrage zu verwendeten Programmiersprachen liegt Python mit 49,2\% auf Platz drei \autocite[vgl.][]{yepis_2023_2023}.
Das bedeutet, dass knapp die Hälfte der befragten Entwickler unter anderem Python verwenden, somit ist eine ausreichende Verbreitung gewährleistet.
Die Verbreitung ist vorallem deshalb ein wichtiger Aspekt, da es durch eine hohe Verbreitung ein großes Eco-System mit viele quelloffene Ressourcen und bereits durchgeführte Projekte gibt.

Um Machine-Learning mit Python zu betreiben, gibt es mehrere Bibliotheken zur Auswahl.
Die 3 bekanntesten Open-Source-Bibliotheken sind dabei \gqq{TensorFlow}, \gqq{PyTorch} und \gqq{SciKit-Lern} \autocite[vgl.][]{msv_tensorflow_nodate}.

Diese Bibliotheken sind sich relativ ähnlich.
Vorteile einer Bibliothek bringen automatisch auch Nachteile, die sich somit gegenseitig aufheben.

Der wesentliche Unterschied zwischen den Bibliotheken ist, dass die Entwickler dieser Studienarbeit bereits Vorkenntnisse in Tensorflow haben, weshalb Tensorflow verwendet wird.
Zusätzlich wird das Modul \gqq{Keras} verwendet, welches eine entwicklerfreundliche High-Level-Schnittstelle für Tensorflow ist und somit eine einfachere Entwicklung ermöglicht \autocite[vgl.][]{noauthor_keras_nodate}.

\subsubsection{Demosystem}

\subsection{Versuchssystem}

\subsubsection{Feature Kombination}
Wie bereits in Kapitel~\ref{sec:FeatureKombination} erwähnt müssen zuerst die Konfigurationen erzeugt werden.
Hierzu werden die vorher definierten Werte in einer JSON Datei erfasst und durch ein Tool werden alle möglichen Konfiguration mit einer ID erzeugt.
Hierbei muss beachtet werden, dass durch die Kombination Konfigurationen entstehen in welchen, nichts berechnet werden muss.
Die erstellte JSON Datei ist in dem Listing~\ref{configs} dargestellt.
\begin{lstlisting}[language=JavaScript,numbers=none,caption=Konfigurationsmöglichkeiten,label=configs]
Configs = {
    "amount_of_frames": [10000, 15000],
    "size_of_frame": [400, 600],
    "LPC": {
        "order": [13, 20],
        "weight": [0, 1]
    },
    "MFCC": {
        "order": [13, 20],
        "weight": [0, 1]
    },
    "LPCC": {
        "order": [13, 20],
        "weight": [0, 1]
    },
    "delta_MFCC": {
        "order": [13],
        "weight": [0, 1]
    }
}
\end{lstlisting}
Der \codestyle{weight} Parameter gibt lediglich an ob in dieser Konfiguration dieses Feature verwendet werden soll oder nicht.

\subsubsection{Datensatz}
Für die Evaluierung der Stimmmerkmale wird ein geeigneter Datensatz benötigt.
Hierzu wurde nach einer Internetrecherche auf der Plattform \gqq{Kaggle} ein entsprechender Datensatz gefunden, der die Anforderung aus Kapitel~\ref{sec:KonzeptDatensatz} erfüllt. \autocite[vgl.][]{jain_speaker_2019}
Der Originaldatensatz enthält Audiodaten zu 50 Sprechern mit mindestens 60 Minuten Aufzeichnung pro Sprecher in mehreren kompressionslosen WAV Dateien.

In einem ersten Schritt müssen die Daten aufbereitet werden.
Der Originaldatensatz lässt sich in zwei Teile teilen, während der erste Teil aus YouTube Videos besteht, sind im zweiten Teil Aufnahmen von englischen Hörbüchern enthalten.
Da die Aufnahmequalität der Hörbücher deutlich besser ist, wurden nur diese Datensätze weiterverwendet.
In einem Folgeschritt werden die einzelnen Dateien der Datensätze zu einer Datei zusammengefügt und genauer betrachtet.
Hierbei konnten längere Pausen und Abweichungen der Datensätze, wie z.B. mehrere Sprecher oder eine andere Sprache identifiziert werden.
Diese Pausen wurden entfernt und die betroffenen Datensätze aus dem Datensatz entfernt.
Dadurch bleiben 25 geeignete Datensätze übrig, aus diesen wurden unter dem Aspekt des Geschlechts 20 Datensätze ausgewählt, sodass neun weibliche und elf männliche Sprecher im finalen Datensatz sind, da nur neun weibliche Datensätze geeignet sind.
Abschließend wurde für jeden Sprecher eine Audiodatei zum Trainieren des neuronalen Netzes mit acht Minuten erstellt und zur Evaluation 5 Sequenzen mit jeweils 15 Sekunden.
Das Testmaterial ist nicht im Trainingsmaterial enthalten.

\subsubsection{Vorverarbeitung und Feature Extraktion}

Um eine effektive Verarbeitung eines Audiosignals zu ermöglichen, muss zunächst eine Vorverarbeitung des Signals erfolgen(s. Kapitel~\ref{sec:preprocessing})
% librosa load
% remove silence 
% noice_reduce#

% berechnung der Merkmale für Trainings- und Testdaten --> benötigt für Traditionellen Authentifizierungsprozess

\subsubsection{Klassifikation und Evaluierung}
In dem Kapitel~\ref{sec:KonzeptKlassifikation} wurden neuronale Netze als Klassifikationsmodell gewählt, um die zuvor berechneten Merkmale zu evaluiert.
Hierbei werden zuerst neuronale Netze mit den berechneten Trainingsdaten trainiert, diese Netze bestehen aus drei Hidden-Layer mit jeweils 128, 64 und 32 Neuronen.
% TODO  @Johannes verifizieren am besten mit Quelle
Wie bereits im Konzept dargestellt müssen mehrere neuronale Netze trainiert werden, in diesem Fall werden für jede Konfiguration drei neuronale Netze erstellt.

Nach dem Training erfolgt die Evaluation der neuronalen Netze, hierzu wird der tatsächliche Authentifizierungsprozess nachgebildet.
Die berechneten Testdaten werden nun auf die neuronalen Netze angewandt, sprich das neuronale Netz klassifiziert die Daten.
Daraus erhält man die Anzahl der zugeordneten Merkmale zu jedem Sprecher pro Testdatei.
Aufgrund der unterschiedlichen Anzahl Merkmale je nach Konfiguration müssen die Werte normiert werden, dazu wird die absolute Zuordnung in eine relative umgerechnet.
Da für jeden Sprecher fünf Testdateien vorliegen entstehen pro neuronales Netz 100 Datensätze und für jede Konfiguration somit 300.

Nach Abschluss der Klassifikationen aller Features können diese Datensätze ausgewertet werden und somit ein Rückschluss auf die beste Merkmalskombination getroffen werden.
Die Durchführung und Evaluation des Versuchs sind in Kapitel~\ref{sec:Evaluation} dargestellt.


\subsection{Demosystem}