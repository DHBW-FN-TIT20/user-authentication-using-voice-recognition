\section{Analyse der Sicherheitsrisiken}\label{sec:Sicherheitsrisiken}
In dem vorliegenden Kapitel wird die Analyse der Sicherheitsrisiken von Sprecherauthentifikationssystemen durchgeführt.
Dazu werden mögliche Angriffsszenarien und entsprechende Gegenmaßnahmen vorgestellt.
Dabei wird die Analyse zunächst auf ein allgemeines System und die erarbeiteten Sicherheitsrisiken dann auf das entwickelte Demosystem bezogen.
Dies ist möglich, da das Demosystem, dessen Entwicklungen in den vorausgegangenen Kapiteln beschrieben wurde, von diesem allgemeinen System abgeleitet ist.

\subsection{Allgemeine Sicherheitsrisiken}
In diesem Abschnitt erfolgt die Analyse der Sicherheitsrisiken für ein allgemeines Sprecherauthentifikationssystem.
Hierbei geht es speziell um Bedrohungen von Sprecherauthentifikationssystemen, allgemeine Risiken von IT-Systemen werden nicht näher beachtet.
Ein solches System wird in Kapitel~\ref{sec:allgemeiner_system_aufbau} dargestellt und erläutert.
Grundsätzlich gibt es drei Arten von Sicherheitsrisiken für Sprecherauthentifikationssysteme: Voice-Spoofing, Backdoor-Attacken und Eavesdropping.
Im Folgenden sind diese drei Sicherheitsrisiken dargestellt und erläutert.

Voice Spoofing bezieht sich auf die Nachahmung einer bestimmten Stimme oder die Manipulation einer Sprachaufnahme um so jemanden zu täuschen oder Zugriff auf ein System zu erhalten.
Die Nachahmung der Stimme wird auch als synthetische Stimmimitation bezeichnet.
Eine Untersuchung der Universität of Birmingham in Alabama zeigt, dass bereits wenige Minuten Audio des Opfers ausreichen, um die Stimme vollständig zu klonen.
Auch die Optionen zur Beschaffung dieser Informationen werden präsentiert.
Der Angreifer kann sich in der Nähe des Opfers aufhalten und Sprachaufnahmen machen, im Internet nach Aufnahmen suchen oder gezielt über Spam-Anrufe die benötigten Daten erhalten \autocite[vgl.][]{katherine_shonesy_uab_2015}.

Die Manipulation einer Sprachaufnahme bedeutet das Anpassen, beziehungsweise das Bearbeiten, des ursprünglichen Audiosignals.
Guangke Chen setzt in seinem Angriffssystem \gqq{FakeBob} auf Pertubation.
Hierbei wird auf ein Audio Quellsignal eine Störung angewandt, die es ermöglicht, dass das attackierte Sprecherauthentifikationssystem einen anderen Benutzer authentifiziert.
Dabei ist es für einen Menschen nicht möglich, einen Unterschied zwischen der originalen Aufnahme und der veränderten Aufnahme wahrzunehmen, wodurch der Angriff vertuschbar ist.
\gqq{FakeBob} attackiert hierbei im Black-Box Modus und hat somit lediglich Zugang zum Authentifizierungsergebnis und bei zwei von drei Versuchssystemen auf die Ergebnisverteilung.
Im Rahmen der Arbeit wird \gqq{FakeBob} auf das Open-Source System \gqq{Kaldi} und auf die kommerziellen Systeme \gqq{Talentedsoft} und \gqq{Microsoft Azure} angewandt.
\gqq{FakeBob} erzielt hierbei eine 100~\% Attack-Succes-Rate bei \gqq{Kaldi} und \gqq{Talentedsoft}, welche sowohl die Verteilung als auch die Entscheidung bereitstellen.
Bei \gqq{Microsoft Azure} steht nur die Entscheidung zur Verfügung.
Hier erreicht \gqq{FakeBob} eine Attack-Success-Rate von 26~\% \autocite[vgl. ][]{chen_who_2020}.

Um biometrischen Spoofing Attacken entgegenzuwirken, gibt es eine sogenannte \ac{PAD}.
\ac{PAD} verwendet verschiedene Techniken und Algorithmen, um gefälschte oder vorab aufgezeichnete Sprachaufnahmen zu identifizieren \autocite[vgl. ][]{paravision_introduction_2022}

Backdoor Attacken beschreiben das Vorgehen, bei dem der Hacker gezielt die Trainingsdaten verändert, um somit eine Hintertür zu schaffen, über die das System infiltriert werden kann.
Die Untersuchungen von Tongqing Zhai zeigen ein solches Verfahren auf.
Hierzu bearbeitet der Hacker den Trainingsdatensatz, ohne Kenntnis über den eigentlichen Anmeldungsprozess.
In der Arbeit werden unterschiedliche Ansätze zur Veränderung auf zwei Datensätzen durchgeführt.
Hierbei werden Attack Success Rates zwischen mindestens 45~\% und maximal 99,5~\% erreicht \autocite[vgl. ][]{zhai_backdoor_2021}

Um sich vor Backdoor Attacken zu schützen, kann die Integrität des Datensatzes überprüft werden, um so Manipulationen zu identifizieren.
Dies kann beispielsweise durch ein Prüfsummen Verfahren realisiert werden.

Eavesdropping bezeichnet im Allgemeinen das Abhören.
Dies kann in Bezug auf Sprecherauthentifikationssysteme auf unterschiedliche Art und Weise durchgeführt werden.
Grundsätzlich kann der zu authentifizierende Sprecher direkt aufgenommen werden.
Hierzu eignen sich beispielsweise Telefongespräche oder Fake-Interviews.
Diese Aufnahme kann im Anschluss zur Authentifizierung am System verwendet werden.
Alternativ können Angreifer auf online Sprach- bzw. Videoaufnahmen zurückgreifen.

Ein weiterer Ansatz ist das klassische Eavesdropping, hierbei spioniert der Angreifer die Kommunikationsverbindung zwischen Benutzer und System aus und zeichnet diese auf.
Mit dieser Aufzeichnung kann er sich zu späterem Zeitpunkt ebenfalls am System anmelden.

Um oben genannte Eavesdropping Angriffe zu vermeiden, kann vor das Sprecherauthentifikationssystem eine Texterkennung geschaltet werden.
Somit kann durch Vorgabe eines Satzes überprüft werden, ob es sich um eine Aufnahme handelt.
Das klassische Eavesdropping lässt sich durch die Verwendung von verschlüsselten Kommunikationsverbindungen vermeiden.

\subsubsection{Einordnen in die STRIDE-Kategorien}
% TODO Muss Mann das belegen was das ist?
Im Folgenden werden die oben genannten Sicherheitsrisiken in die STRIDE-Kategorien eingeordnet.
Wie bereits oben genannt, werden lediglich spezielle Bedrohungen von Sprecherauthentifikationssystemen behandelt.
STRIDE steht für sechs verschiedene Kategorien zur Bewertung von Sicherheitsrisiken für IT-Systeme (s. Kapitel~\ref{sec:stride}).
% textuell: Paragraph pro Kategorie
\paragraph{Spoofing}
Wie im Namen enthalten fällt unter Spoofing das Voice Spoofing.
Das Risiko besteht darin, dass die Stimme eines autorisierten Sprechers nachgeahmt wird, oder eine manipulierte Sprachaufnahme verwendet wird.

\paragraph{Tampering}
Tampering bedeutet zu Deutsch Manipulation.
Deshalb fällt das Voice Spoofing ebenfalls in die Kategorie Tampering.
Ebenso fällt die Backdoor Attacke in diese Kategorie, da hierbei die Trainingsdaten gezielt manipuliert werden.

\paragraph{Repudiation}
Repudiation bezieht sich auf die Fähigkeit Aktionen innerhalb des Systems zu leugnen, somit kann die Integrität des Systems infrage gestellt werden.
Diese Kategorie findet jedoch auf allgemeine Bedrohungen für Sprecherauthentifikationssystemen keine Anwendung.

\paragraph{Information Disclosure}
Information disclosure beschreibt die Offenlegung von vertraulichen Daten.
Dies kann durch Eavesdropping Angriffe auftreten, da ein Angreifer durch Aufzeichnung von Authentifizierungsinformationen Zugang zum System erhalten kann.

\paragraph{Denial of Service}
Denial of service bedeutet \gqq{Verweigerung des Dienstes}.
Bei einer solchen Attacke wird gezielt das System überlastet, um einen Ausfall zu provozieren.
Diese Kategorie findet wie Repudiation keine Anwendung auf allgemeine Bedrohungen für Sprecherauthentifikationssystemen.

\paragraph{Elevation of Privilege}
Elevation of privilege beschreibt das Erlangen zusätzlicher Berechtigungen um so Zugang zu weiteren Ressourcen zu erhalten.
In diese Kategorie fällt die Backdoor Attacke, da der Angreifer gezielt die Trainingsdaten verändert, um eine Hintertür zu schaffen, sodass er das System infiltrieren kann.



\subsubsection{DREAD-Analyse}
Im vorliegenden Kapitel werden die zuvor ermittelten Risiken mit der DREAD-Methodik bewertet.
Die DREAD-Methodik ermöglicht den Schweregrad bzw. das Risiko des Angriffs zu messen.
% TODO evtl noch in grundlagen ergänzen.
Die Ergebnisse sind in der Tabelle \ref{tab:dread-analyse} dargestellt.

\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}

\begin{landscape}
    \begin{table}[]
        \centering
        \begin{tabular}{|L{1cm}|L{3cm}|L{3cm}|L{1.7cm}|L{1.7cm}|L{1.7cm}|L{1.7cm}|L{1.7cm}|L{1.7cm}|L{1.7cm}|}
            \hline
            ID &
              Grundsätzliches Sicherheitsrisiko &
              \textbf{Attackierungs\-möglichkeit} &
              STRIDE Ein\-stufung &
              Damage &
              Re\-pro\-ducibil\-i\-ty &
              Ex\-ploitabil\-i\-ty &
              Affected Users &
              Dis\-cov\-er\-abil\-i\-ty &
              \textbf{Average} \\ \hline
            1                                 & Voice Spoofing   & \textbf{Synthetische Stimme}                                   & ST & 8 & 8 & 3  & 1  & 3  & \textbf{4,6} \\ \hline
            2                                 & Voice Spoofing   & \textbf{Manipulation der Stimme durch Störung}                 & ST & 8 & 7 & 3  & 1  & 5  & \textbf{4,8} \\ \hline
            3                                 & Backdoor Attacke & \textbf{Manipulation der Trainingsdaten für Backdoor}          & TE & 9 & 3 & 2  & 10 & 4  & \textbf{5,6} \\ \hline
            4                                 & Eavesdropping    & \textbf{Aufzeichnen des Opfers}                                & I  & 8 & 8 & 8  & 1  & 10 & \textbf{7}   \\ \hline
            5                                 & Eavesdropping    & \textbf{Verwenden von vorhandenen Sprach- oder Videoaufnahmen} & I  & 8 & 6 & 10 & 1  & 10 & \textbf{7}   \\ \hline
            6                                 & Eavesdropping    & \textbf{Aufzeichnen der Verbindung zwischen Client und Server} & I  & 8 & 5 & 5  & 1  & 9  & \textbf{5,6} \\ \hline
        \end{tabular}
        \caption{DREAD-Analyse}
        \label{tab:dread-analyse}
    \end{table}
\end{landscape}

Die Tabelle stellt die STRIDE-Einstufung aus dem vorangegangenen Kapitel und die DREAD-Methodik dar.
In der letzten Spalte werden die Ergebnisse der Untersuchung aufgezeigt, hierbei steht eine hohe Zahl für ein hohes Risiko, für dieses Szenario.
Bei einer Entwicklung als Produktivsystem sollten diese Risiken beachtet werden und durch die ebenfalls vorhin genannten Möglichkeiten zum Schutz vor solchen Angriffen reduziert werden.

% Übersichststabelle und dann gleich mit DREAD Bewertung

\subsection{Bezug zum Demosystem}

Das in Kapitel~\ref{sec:umsetzung_demo} entwickelte Demosystem unterscheidet sich gravierend von einer Produktivlösung.
Dieses System wurde ausschließlich dazu entwickelt, um die Ergebnisse aus dem Versuchssystem anhand eines praktischen Authentifizierungsablaufs darzustellen und kann auf keinen Fall mit einem ausgereiften System verglichen werden.
Die oben genannte Sicherheitsrisiken existieren somit nicht für das Demosystem, da zum einen keine externen Eingaben wie Stimm-Aufnahmen ins System gegeben werden können und das System zum anderen keine persönlichen oder kritischen Daten schützt.

Wenn das System als Produktivlösung implementiert werden würde, müssten die oben genannten Maßnahmen zur Risikominimierung berücksichtigt werden.
Zusätzlich müssten zu den oben genannten speziellen Sicherheitsrisiken auch allgemeine Sicherheitsrisiken für ein solches Authentifikationssystem bewertet werden.


\textauthor{\vLB}{}{}

