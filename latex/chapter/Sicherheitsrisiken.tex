\section{Analyse der Sicherheitsrisiken}
In dem vorliegenden Kapitel wird die Analyse der Sicherheitsrisiken von Sprecherauthentifikationssystemen durchgeführt.
Dazu werden mögliche Angriffsszenarien und entsprechende Gegenmaßnahmen vorgestellt.
Dabei wird die Analyse zunächst auf ein allgemeines System bezogen und die erarbeiteten Sicherheitsrisiken dann auf das entwickelte Demosystem bezogen.
Dies ist möglich, da das Demosystem, dessen Entwicklungen in den vorausgegangenen Kapiteln beschrieben wurde, von diesem allgemeinen System abgeleitet ist.

\subsection{Allgemeine Sicherheitsrisiken}
In diesem Abschnitt erfolgt die Analyse der Sicherheitsrisiken für ein allgemeines Sprecherauthentifikationssystem.
Hierbei geht es speziell um Bedrohungen von Sprecherauthentifikationssystemen, allgemeine Risiken von IT-Systemen werden nicht näher beachtet.
Ein solches System wird in Kapitel~\ref{sec:allgemeiner_system_aufbau} dargestellt und erläutert.
Grundsätzlich gibt es drei Arten von Sicherheitsrisiken für Sprecherauthentifikationssysteme: Voice-Spoofing, Backdoor-Attacken und Eavesdropping.
Im Folgenden sind diese drei Sicherheitsrisiken dargestellt und erläutert.

Voice Spoofing bezieht sich auf die Nachahmung einer bestimmten Stimme oder die Manipulation einer Sprachaufnahme um so jemanden zu täuschen oder Zugriff auf ein System zu erhalten.
Die Nachahmung der Stimme wird auch als synthetische Stimmimitation bezeichnet.
Eine Untersuchung der Universität of Birmingham in Alabama zeigt, dass bereits wenige Minuten Audio des Opfers ausreichen, um die Stimme vollständig zu klonen.
Auch die Optionen zur Beschaffung dieser Informationen werden präsentiert.
Der Angreifer kann sich in der Nähe des Opfers aufhalten und Sprachaufnahmen machen, im Internet nach Aufnahmen suchen oder gezielt über Spam-Anrufe die benötigten Daten erhalten \autocite[vgl.][]{katherine_shonesy_uab_2015}.

Die Manipulation einer Sprachaufnahme bedeutet das Anpassen, beziehungsweise das Bearbeiten, des ursprünglichen Audiosignals.
Guangke Chen setzt in seinem Angriffssystem \gqq{FakeBob} auf Pertubation.
Hierbei wird auf ein Audio Quellsignal eine Störung angewandt, die es ermöglicht, dass das attackierte Sprecherauthentifikationssystem einen anderen Benutzer authentifiziert.
Dabei ist es für einen Menschen nicht möglich, einen Unterschied zwischen der originalen Aufnahme und der veränderten Aufnahme wahrzunehmen, wodurch der Angriff vertuschbar ist.
\gqq{FakeBob} attackiert hierbei im Black-Box Modus und hat somit lediglich Zugang zum Authentifizierungsergebnis und bei zwei von drei Versuchs-Systemen auf die Ergebnisverteilung.
Im Rahmen der Arbeit wird \gqq{FakeBob} auf das Open-Source System \gqq{Kaldi} und auf die kommerziellen Systeme \gqq{Talentedsoft} und \gqq{Microsoft Azure} angewandt.
\gqq{FakeBob} erzielt hierbei eine 100~\% Attack-Succes-Rate bei \gqq{Kaldi} und \gqq{Talentedsoft}, welche sowohl die Verteilung als auch die Entscheidung bereitstellen.
Bei \gqq{Microsoft Azure} steht nur die Entscheidung zur Verfügung.
Hier erreicht \gqq{FakeBob} eine Attack-Success-Rate von 26~\% \autocite[vgl. ][]{chen_who_2020}.

Um biometrischen Spoofing Attacken entgegenzuwirken, gibt es eine sogenannte \ac{PAD}.
\ac{PAD} verwendet verschiedene Techniken und Algorithmen, um gefälschte oder vorab aufgezeichnete Sprachaufnahmen zu identifizieren \autocite[vgl. ][]{paravision_introduction_2022}

Backdoor Attacken beschreiben das Vorgehen, bei dem der Hacker gezielt die Trainingsdaten verändert, um somit eine Hintertür zu schaffen, über die das System infiltriert werden kann.
Die Untersuchungen von Tongqing Zhai zeigen ein solches Verfahren auf.
Hierzu bearbeitet der Hacker den Trainingsdatensatz, ohne Kenntnis über den eigentlichen Anmeldungsprozess.
In der Arbeit werden unterschiedliche Ansätze zur Veränderung auf zwei Datensätzen durchgeführt.
Hierbei werden Attack Success Rates zwischen mindestens 45~\% und maximal 99,5~\% erreicht \autocite[vgl. ][]{zhai_backdoor_2021}

Um sich vor Backdoor Attacken zu schützen, kann die Integrität des Datensatzes überprüft werden, um so Manipulationen zu identifizieren.
Dies kann beispielsweise durch ein Prüfsummen Verfahren realisiert werden.

Eavesdropping bezeichnet im Allgemeinen das Abhören.
Dies kann in Bezug auf Sprecherauthentifikationssysteme auf unterschiedliche Art und Weise durchgeführt werden.
Grundsätzlich kann der zu authentifizierende Sprecher direkt aufgenommen werden.
Hierzu eignen sich beispielsweise Telefongespräche oder Fake-Interviews.
Diese Aufnahme kann im Anschluss zur Authentifizierung am System verwendet werden.
Alternativ können Angreifer auf online Sprach- bzw. Videoaufnahmen zurückgreifen.

Ein weiterer Ansatz ist das klassische Eavesdropping, hierbei spioniert der Angreifer die Kommunikationsverbindung zwischen Benutzer und System aus und zeichnet diese auf.
Mit dieser Aufzeichnung kann er sich zu späterem Zeitpunkt ebenfalls am System anmelden.

Um oben genannte Eavesdropping Angriffe zu vermeiden, kann vor das Sprecherauthentifikationssystem eine Texterkennung geschaltet werden.
Somit kann durch Vorgabe eines Satzes überprüft werden, ob es sich um eine Aufnahme handelt.
Das klassische Eavesdropping lässt sich durch die Verwendung von verschlüsselten Kommunikationsverbindungen vermeiden.

\subsubsection{Einordnen in die STRIDE-Kategorien}
% TODO Muss Mann das belegen was das ist?
Im Folgenden werden die oben genannten Sicherheitsrisiken in die STRIDE-Kategorien eingeordnet.
Wie bereits oben genannt, werden lediglich spezielle Bedrohungen von Sprecherauthentifikationssystemen behandelt.
STRIDE steht für sechs verschiedene Kategorien zur Bewertung von Sicherheitsrisiken für IT-Systeme (s. Kapitel~\ref{sec:stride}).
% textuell: Paragraph pro Kategorie
\paragraph{Spoofing}
Wie im Namen enthalten fällt unter Spoofing das Voice Spoofing.
Das Risiko besteht darin, dass die Stimme eines autorisierten Sprechers nachgeahmt wird, oder eine manipulierte Sprachaufnahme verwendet wird.

\paragraph{Tampering}
Tampering bedeutet zu Deutsch Manipulation.
Deshalb fällt das Voice Spoofing ebenfalls in die Kategorie Tampering.
Ebenso fällt die Backdoor Attacke in diese Kategorie, da hierbei die Trainingsdaten gezielt manipuliert werden.

\paragraph{Repudiation}
Repudiation bezieht sich auf die Fähigkeit Aktionen innerhalb des Systems zu leugnen, somit kann die Integrität des Systems infrage gestellt werden.
Diese Kategorie findet jedoch auf allgemeine Bedrohungen für Sprecherauthentifikationssystemen keine Anwendung.

\paragraph{Information disclosure}
Information disclosure beschreibt die Offenlegung von vertraulichen Daten.
Dies kann durch Eavesdropping Angriffe auftreten, da ein Angreifer durch Aufzeichnung von Authentifizierungsinformationen Zugang zum System erhalten kann.

\paragraph{Denial of service}
Denial of service bedeutet \gqq{Verweigerung des Dienstes}.
Bei einer solchen Attacke wird gezielt das System überlastet, um einen Ausfall zu provozieren.
Diese Kategorie findet wie Repudiation keine Anwendung auf allgemeine Bedrohungen für Sprecherauthentifikationssystemen.

\paragraph{Elevation of privilege}
Elevation of privilege beschreibt das Erlangen zusätzlicher Berechtigungen um so Zugang zu weiteren Ressourcen zu erhalten.
In diese Kategorie fällt die Backdoor Attacke, da der Angreifer gezielt die Trainingsdaten verändert, um eine Hintertür zu schaffen, sodass er das System infiltrieren kann.



\subsubsection{DREAD-Analyse}

% Übersichststabelle und dann gleich mit DREAD Bewertung

\subsection{Bezug zum Demosystem}

% textuell

































































